# üìä Guide d'√âvaluation par Batch

Ce guide vous explique comment √©valuer vos mod√®les par batch pour optimiser l'utilisation de la RAM.

## üéØ Vue d'Ensemble

L'√©valuation par batch r√©sout le probl√®me de RAM insuffisante en :
- üîÑ Divisant les mod√®les en groupes (batches)
- üßπ Vidant le cache entre les batches
- üìä Consolidant les r√©sultats finaux
- üé® G√©n√©rant les graphiques de comparaison

## üìÅ Nouveaux Scripts Disponibles

| Script | Description | Usage Principal |
|--------|-------------|-----------------|
| `batch_evaluation.py` | √âvaluation par batch manuelle | Contr√¥le pr√©cis des batches |
| `memory_monitor.py` | Surveillance RAM/GPU | Monitoring pendant l'√©valuation |
| `resource_manager.py` | Gestionnaire automatique | Analyse et √©valuation optimis√©e |

## üöÄ Utilisation Rapide

### 1. Mode Automatique (Recommand√©)
```bash
# Analyse automatique + √©valuation optimis√©e
cd evaluation/code
python resource_manager.py --auto --samples 30
```

### 2. Analyse des Ressources Seulement
```bash
# Voir les recommandations sans lancer l'√©valuation
python resource_manager.py --analyze-only
```

### 3. Mode Interactif
```bash
# Menu interactif avec options
python resource_manager.py
```

## üìã Strat√©gies d'√âvaluation

### üèÉ‚Äç‚ôÇÔ∏è Strat√©gie Agressive (RAM > 15GB)
- **Batches larges** : 4-5 mod√®les par batch
- **Temps** : ~1h pour tous les mod√®les
- **Exemples** : Whisper large + plusieurs Wav2Vec2

### ‚öñÔ∏è Strat√©gie Mod√©r√©e (8-15GB RAM)
- **Batches moyens** : 3 mod√®les par batch
- **Temps** : ~1h30 pour tous les mod√®les
- **√âquilibrage** : Mod√®les lourds s√©par√©s

### üêå Strat√©gie Conservative (< 8GB RAM)
- **Petits batches** : 2 mod√®les maximum
- **Temps** : ~2h pour tous les mod√®les
- **S√©curit√©** : √âvite les d√©passements m√©moire

## üõ†Ô∏è Utilisation Avanc√©e

### √âvaluation de Batches Sp√©cifiques
```bash
# √âvaluer seulement les mod√®les Whisper l√©gers
python batch_evaluation.py --batches batch_1_light --samples 20

# √âvaluer plusieurs batches
python batch_evaluation.py --batches batch_1_light batch_2_medium --samples 30
```

### Monitoring en Parall√®le
```bash
# Terminal 1 : Monitoring
python memory_monitor.py --threshold 85 --log-interval 30

# Terminal 2 : √âvaluation
python batch_evaluation.py --samples 30
```

### Lister les Batches Disponibles
```bash
python batch_evaluation.py --list-batches
```

## üìä Organisation des Batches

### Batch 1 - Mod√®les L√©gers (~4GB)
```
- whisper:tiny      (1GB)
- whisper:base      (1GB)
- whisper:small     (2GB)
```

### Batch 2 - Mod√®les Moyens (~10.5GB)
```
- whisper:medium    (5GB)
- wav2vec2:xlsr-53-french (3GB)
- wav2vec2:bhuang-french  (2.5GB)
```

### Batch 3 - Mod√®les Lourds (~20GB)
```
- whisper:large     (10GB)
- whisper:large-v3  (10GB)
```

### Batch 4 - Wav2Vec2 Sp√©cialis√©s (~9GB)
```
- wav2vec2:jonatasgrosman-xlsr      (3.5GB)
- wav2vec2:jonatasgrosman-voxpopuli (3GB)
- wav2vec2:wasertech-cv9            (2.5GB)
```

### Batch 5 - Mod√®les Seamless (~18GB)
```
- seamless:medium   (6GB)
- seamless:large    (12GB)
```

### Batch 6 - Mod√®les Gemma (~23GB)
```
- gemma3n:e2b      (8GB)
- gemma3n:e4b      (15GB)
```

## üîç Monitoring et Optimisation

### M√©triques Surveill√©es
- **RAM** : Utilisation en pourcentage et GB
- **GPU** : M√©moire allou√©e/totale (si CUDA disponible)
- **Swap** : Utilisation du fichier d'√©change
- **Seuils** : Alertes automatiques (d√©faut: 85%)

### Fichiers de Monitoring
```
evaluation/benchmarks/
‚îú‚îÄ‚îÄ memory_stats_TIMESTAMP.json     # Statistiques d√©taill√©es
‚îú‚îÄ‚îÄ batch_X_results_TIMESTAMP.json  # R√©sultats par batch
‚îú‚îÄ‚îÄ consolidated_results_TIMESTAMP.json # R√©sultats finaux
‚îî‚îÄ‚îÄ *.png                           # Graphiques g√©n√©r√©s
```

## ‚ö° Optimisations

### R√©duction de la Consommation M√©moire
1. **R√©duire les √©chantillons** : `--samples 10` au lieu de 30
2. **Vider le cache** : Automatique entre les batches
3. **Mod√®les s√©lectifs** : √âvaluer seulement les mod√®les critiques

### Acc√©l√©ration
1. **GPU VRAM** : D√©charge automatique sur GPU si disponible
2. **Batches parall√®les** : Possible si RAM tr√®s importante (>32GB)
3. **Cache intelligent** : R√©utilisation des transcriptions communes

## üö® Gestion des Erreurs

### RAM Insuffisante
```bash
# Solution 1 : R√©duire la taille des batches
python batch_evaluation.py --batches batch_1_light --samples 10

# Solution 2 : Mode ultra-conservateur
python resource_manager.py  # Choisir option 4 (test rapide)
```

### API Non Accessible
```bash
# V√©rifier l'API
curl http://localhost:8000/health

# Red√©marrer l'API si n√©cessaire
cd ../../api
python start_api.py --host 0.0.0.0 --port 8000
```

### Timeout ou Crash
```bash
# Reprendre o√π on s'est arr√™t√©
python batch_evaluation.py --batches batch_3_heavy batch_4_wav2vec --samples 30
```

## üìà Interpr√©tation des R√©sultats

### Fichiers G√©n√©r√©s
- **`consolidated_results_*.json`** : M√©triques de tous les mod√®les
- **`consolidated_detailed_*.json`** : R√©sultats d√©taill√©s par √©chantillon
- **Graphiques** : Comparaisons automatiques (WER, BLEU, vitesse)

### M√©triques Cl√©s
- **WER** : Plus bas = meilleur (erreurs de mots)
- **BLEU** : Plus haut = meilleur (qualit√© globale)
- **Temps** : Plus bas = plus rapide
- **Succ√®s** : Plus haut = plus fiable

## üéØ Workflow Recommand√©

1. **Analyse initiale**
   ```bash
   python resource_manager.py --analyze-only
   ```

2. **Test rapide** (pour v√©rifier que tout fonctionne)
   ```bash
   python resource_manager.py --auto --samples 5
   ```

3. **√âvaluation compl√®te**
   ```bash
   python resource_manager.py --auto --samples 30
   ```

4. **Analyse des r√©sultats**
   - Consulter les graphiques g√©n√©r√©s
   - Examiner `consolidated_results_*.json`
   - V√©rifier les statistiques de m√©moire

## üí° Conseils Pratiques

### Pour Syst√®mes avec RAM Limit√©e (< 8GB)
- Utiliser `--samples 10` maximum
- √âvaluer 1-2 mod√®les √† la fois
- Surveiller le swap activement

### Pour Syst√®mes Performants (> 16GB)
- Utiliser `--samples 50` pour plus de pr√©cision
- Batches plus larges possibles
- Monitoring moins critique

### Pour Tests de D√©veloppement
- Utiliser `--samples 5` pour des tests rapides
- Se concentrer sur 2-3 mod√®les repr√©sentatifs
- It√©rer rapidement

## üîß Personnalisation

### Modifier les Estimations M√©moire
√âditez `resource_manager.py` ligne ~60 :
```python
def get_model_memory_estimates(self) -> Dict[str, float]:
    return {
        "whisper:tiny": 1.0,    # Ajustez selon vos observations
        "whisper:base": 1.0,
        # ... autres mod√®les
    }
```

### Ajuster les Seuils
```bash
# Seuil d'alerte RAM plus strict
python memory_monitor.py --threshold 75

# Intervalle de monitoring plus fr√©quent
python memory_monitor.py --log-interval 15
```

### Cr√©er des Batches Personnalis√©s
Modifiez `batch_evaluation.py` ligne ~40 pour d√©finir vos propres groupes de mod√®les.

---

Ce syst√®me vous permet d'√©valuer tous vos mod√®les de mani√®re optimis√©e, m√™me avec des ressources limit√©es ! üöÄ 